{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 4580/5580 - Data Science – Fall 2020\n",
    "## Lab 8: Deep Learning\n",
    "\n",
    "#### **Student Full Name**:\n",
    "\n",
    "#### **Student ID**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTANT\n",
    "For this lab, I highly recommend using the Anaconda environment.\n",
    "\n",
    "In order to properly run this lab, we will need to run a few configuration steps to configure a special environment for loading Keras/Tensorflow.\n",
    "\n",
    "## Step 1:\n",
    "We will create a new `conda` environment for Tensorflow. This is because some Tensorflow dependencies conflict with those installed in the `base` conda environment. \n",
    "\n",
    "Open a Terminal/command prompt and type:\n",
    "\n",
    "```conda create -n tf tensorflow pandas numpy matplotlib jupyter```\n",
    "\n",
    "This will create a new virtual environment called `tf` with installed packages `tensorflow`,`pandas`,`numpy`, and `matplotlib`, and `jupyter`. These are the most commonly used packages needed to do the assignment. You should not need any other packages for this lab.\n",
    "\n",
    "Your terminal should look similar to the below:\n",
    "\n",
    "![conda_install](imgs/conda_install.png)\n",
    "\n",
    "Anaconda will generate a list of required packages and ask you for confirmation to install. Type `y` to continue.\n",
    "\n",
    "![conda_confirm](imgs/install_confirm.png)\n",
    "\n",
    "Once install is finished, you should activate your new environment by running: \n",
    "\n",
    "`conda activate tf`\n",
    "\n",
    "![conda_activate](imgs/conda_activate.png)\n",
    "\n",
    "You should see that the environment has activated successfully if `(tf)` appears before your terminal string.\n",
    "\n",
    "Finally, navigate to the directory containing the Lab 8 notebook, and run `jupyter notebook`.\n",
    "\n",
    "![open_jupyter](imgs/open_jupyter.png)\n",
    "\n",
    "Done!\n",
    "\n",
    "You should close the version of this notebook that is open in your base anaconda environment, and continue the assignment using the version from the `tf` virtualenv.\n",
    "\n",
    "**NOTE:** If you leave and come back to the assignment, remember to run `conda activate tf` in your terminal to activate the correct `conda` environment **before** running `jupyter notebook`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deliverables\n",
    "Complete all the exercises below and turn in a write up in the form of a Jupyuter notebook, that is, an **.ipynb file**.\n",
    "The write up should include your code, answers to exercise questions, and plots of results.\n",
    "Submit the assignment on Canvas under \"Lab 8\", with this file (after your edits) as an attachment. \n",
    "\n",
    "Notes:\n",
    "\n",
    "1. You have to use this notebook and fill in answers inline. \n",
    "\n",
    "2. Please do not add or remove any cells (you can add cells while doing the homework but remove them before submission).\n",
    "\n",
    "3. In this notebook, we provide code templates for many of the exercises. They are intended to help with code re-use, since the exercises build on each other. Don't forget to include answers to questions that ask for natural language responses, i.e., in English, not code!\n",
    "\n",
    "4. We will test your code automatically, so in your submitted notebook function names must conform with the names requested by the questions. Also you should make sure we can execute your notebook by running \"Cell > Run all\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need Help? \n",
    "In case you need help with this assignment, please ask your questions on the designated channel for Lab 8 on Microsoft Teams. This way, you may receive assistance from the TA’s or your classmates (<b>DO NOT share your solution</b>) [Recommended]. \n",
    "<br/>If you need to include your solution in your question, please create a new chat with <b>all the TA’s</b>. In the new chat, add all the TA’s rather than sending your question to the TA’s separately.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaboration\n",
    "This assignment is to be done individually. Everyone should be getting a hands on experience in this course. You are free to discuss course material with fellow students, and we encourage you to use resources on the Internet to aid your understanding, but the work you turn in, including all code and answers, must be your own work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's Get Started!\n",
    "===\n",
    "\n",
    "## Overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Neural Networks are powerful data-driven models, which can learn complex, non-linear representations of data. \n",
    "![Simple Neural Network Image](imgs/simple_neural_network.png)\n",
    "The field of Deep Learning (DL) involves applying large neural networks to solve learning problems like classification, image segmentation, text translation and summarization, and many others. The field of Deep Learning is large, and constantly growing. Although we couldn't hope to provide a complete overview of Deep Learning in a single lab assignment, we have chosen to work with two ubiquitous DL models: \n",
    "- Deep Neural Networks - DNN\n",
    "- Convolutional Neural Networks - CNN\n",
    "\n",
    "These two model architectures are two of the oldest and simplest architectures within DL literature. In this lab, we will experiment both a DNN and CNN architecture. Because not everyone owns their own GPU-equipped compute cluster we will be using scaled-down versions of these architectures, which are trainable on a laptop within a few minutes or less!\n",
    "\n",
    "Although we cannot provide a complete background of the math behind neural networks here, each of the two sections has a small introduction that provides some of the basic required knowledge.\n",
    "\n",
    "For an excellent deep-dive into the math behind Deep Learning with applications for Convolutional Neural Networks, check out the [CS231N - Convolutional Neural Networks for Image Recognition](https://cs231n.github.io/convolutional-networks/) course from Stanford. This course also has an associated video lecture series in [this YouTube playlist](https://www.youtube.com/watch?v=vT1JzLTH4G4&list=PLC1qU-LWwrF64f4QKQT-Vg5Wr4qEE1Zxk).\n",
    "\n",
    "This course provides lectures about:\n",
    "- Introduction to Neural Networks\n",
    "- Image Classification\n",
    "- Loss Functions/Optimization\n",
    "- Computational Graphs and Backpropogation\n",
    "- and much more!\n",
    "\n",
    "Another great resource for learning about Deep Learning is the [Deep Learning Book from MIT Press](https://www.deeplearningbook.org/). This book is free to access online, and contains information about many types of architectures and fields of research within Deep Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Application\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Learning Architectures can be applied in virtually any application domain. Convolutional architectures can be used for object recognition, or to perform object recognition and tracking within images or videos. \n",
    "\n",
    "![localize](imgs/localization_detection.png)\n",
    "*Image Credit: [Analytics India Mag](https://analyticsindiamag.com/top-5-image-classification-research-papers-every-data-scientist-should-know/)*\n",
    "\n",
    "Sequence models such as [LSTMs](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) and [Transformer](https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)) architectures can be used to perform text translation, summarization, or other NLP tasks. \n",
    "\n",
    "For the sake of time and ease of learning, we will be using small-scale neural network architectures that we design and implement in the Keras deep learning framework. Keras is a high-level wrapper for Tensorflow, Google's open source Deep Learning library. Tensorflow is an extraordinarily powerful framework, and Keras has distilled many of the most common operations and applications in Tensorflow into a user-friendly API.\n",
    "\n",
    "We will use the same subset of MNIST data that we used for prior labs and assignments in this lab as well. This data contains a total 6000 images from MNIST and also provides a pre-made train/test split, using 4000 images for training and 2000 images for testing/validation.\n",
    "\n",
    "In the following code, you will design and implement a DNN and CNN architecture and evaluate their performance on this MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files\n",
    "\n",
    "Data files for this assignment are provided in the **Data.zip** file available on Canvas.\n",
    "\n",
    "The zip file includes the following files:\n",
    "\n",
    "* **train.fmat.txt**, MNIST Training Images\n",
    "* **ictrain.imat.txt**, MNIST Training Labels\n",
    "* **test.fmat.txt**, MNIST Testing Images\n",
    "* **ictest.imat.txt**, MNIST Testing Labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Preliminaries\n",
    "Download the data from Canvas and uncompress/unarchive it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras\n",
    "# Required if you are running on MacOS\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q0 [10 points]\n",
    "Load each of the four files into NumPy Array objects. You may use whatever method you like to load the data (we recommend `np.loadtxt`), but your variables must all be NumPy arrays.\n",
    "\n",
    "* `train.fmat.txt` and `test.fmat.txt` are `train_data` and `test_data` respectively.\n",
    "* `ictrain.imat.txt` and `ictest.imat.txt` are `train_labels` and `test_labels` respectively.\n",
    "\n",
    "After loading the data, transpose the data arrays so that each row is a sample/image.\n",
    "\n",
    "The first dimensions of your `train_data` and `train_labels` should match, as well as the first dimensions of `test_data` and `test_labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-10b438c83dd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#test_labels = <your code here>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Test cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_labels' is not defined"
     ]
    }
   ],
   "source": [
    "# Your code here.\n",
    "#train_data = <your code here>\n",
    "#train_labels = <your code here>\n",
    "#test_data = <your code here>\n",
    "#test_labels = <your code here>\n",
    "# Test cases\n",
    "assert(train_labels.shape[0] == 4000)\n",
    "assert(test_labels.shape[0] == 2000)\n",
    "assert(train_data.shape[0] == train_labels.shape[0])\n",
    "assert(test_data.shape[0] == test_labels.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 [10 points]\n",
    "\n",
    "In order to ensure that our data works well inside the DNN, we need to first normalize it so that the pixel values fall in the range $[0,1]$. Create two variables `train_data_norm` and `test_data_norm` to hold the normalized training and testing data, respectively.\n",
    "\n",
    "**HINT:** Currently, the images are grayscale single-channel images with values in the range $[0,255]$.\n",
    "**DOUBLE HINT:** You don't need to use a loop to perform this normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Answer this question\n",
    "#train_data_norm = <your code here>\n",
    "#test_data_norm = <your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 [10 points]\n",
    "The training dataset you loaded in contains `28x28` images of the digits `0-9`. \n",
    "\n",
    "For each of the classes `0-9` compute and display the \"average\" image for that class in the training dataset (i.e. `train_data` and `test_data`). \n",
    "\n",
    "Your code should display exactly 10 images. We recommend using the `plt.subplots` function to generate a figure with 10 subplots, then plotting each digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Answer this question\n",
    "#fig,ax = plt.subplots(<add the arguments>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Dense Neural Network\n",
    "\n",
    "One of the simplest and most generally applicable implementations of a neural network is the Dense Neural Network, or DNN.\n",
    "\n",
    "A DNN is comprised of one or more dense layers, each of which applies a non-linear transformation to the input data.\n",
    "\n",
    "This non-linear transformation is implemented as a weighted sum of each input dimension.\n",
    "\n",
    "For a small example, consider a data matrix $x$ with dimensions $(1,d)$ where $d=4$. The number of rows in this matrix (in this case 1) represents the number of samples in our data. $d$ represents the number of dimensions, which we have set to 4 for this example.\n",
    "$$ x = \\begin{bmatrix}\n",
    "            1 & 2 & 3 & 1\n",
    "        \\end{bmatrix}$$\n",
    "        \n",
    "To perform the non-linear transformation, we will first multiply this vector by a matrix $W$ containing learned weights.\n",
    "\n",
    "$$ W = \\begin{bmatrix}\n",
    "            1 & 0\\\\\n",
    "            0.5 & 1\\\\\n",
    "            0.5 & 2\\\\\n",
    "            0 & 1\n",
    "       \\end{bmatrix}$$\n",
    "       \n",
    "We can multiply $x$ by $W$ in the form:\n",
    "$$ \n",
    "xW = \\begin{bmatrix}\n",
    "            1 & 2 & 3 & 1\n",
    "        \\end{bmatrix}\n",
    "        \\begin{bmatrix}\n",
    "            1 & 0\\\\\n",
    "            0.5 & 1\\\\\n",
    "            0.5 & 2\\\\\n",
    "            0 & 1\n",
    "       \\end{bmatrix}  =  \n",
    "       \\begin{bmatrix}\n",
    "        3.5 & 9\\\\\n",
    "        \\end{bmatrix}\n",
    "      $$\n",
    "      \n",
    "Notice that each column of the weight matrix $W$ applies a separate weighted sum to the dimensions of $x$. Our output matrix has dimensions 1x2 because the matrix $W$ has two columns. The number of rows in $W$ must always match the number of columns in $x$, but the number of columns in $W$ is arbitrary, and defines the *output dimensionality* for our neural network layer.\n",
    "\n",
    "In general, we can regard the operation $xW$ as mapping the data from an $d$-dimensional space to a $m$-dimensional space, where $m$ is the number of columns in weight matrix $W$.\n",
    "\n",
    "If we examine the shapes of both matrices, we can see that the inner dimensions cancel due to the matrix multiplcation:\n",
    "\n",
    "$$ (1,d) * (d,2) = (1,2) $$\n",
    "\n",
    "In this case, we performed the weighted sum operation on a single example. However, we can perform the operation on multiple examples (called a batch) by simply changing the number of samples of our input data. For an input data matrix of shape $(N,4)$, the output $xW$ will always be of shape $(N,2)$ since:\n",
    "\n",
    "$$ (N,4) * (4,2) = (N,2) $$\n",
    "\n",
    "In practice, we refer to $N$ as the *batch size* and $m$ as the number of *output units*.\n",
    "\n",
    "After performing the operation $xW$, we also add a learned bias term $b$, which is a matrix of $(1,m)$. Similar to the intercept term in a linear regression, the value $b$ represents the output value when the weighted sum is 0. \n",
    "\n",
    "Our intermediate output term is:\n",
    "\n",
    "$$ xW+b $$ which encompasses a weighted sum $xW$ followed by an addition $b$.\n",
    "\n",
    "Up until this point, we have simply applied a linear transformation to $x$. The final step is to apply an *activation function*, commonly written as $\\sigma$. The activation function provides a non-linear element to the neural network layer, and is the key to why neural networks can learn more complex functions than other types of models.\n",
    "\n",
    "The final equation for the output of a DNN layer $L$ is:\n",
    "\n",
    "$$ l = \\sigma(xW+b)$$\n",
    "\n",
    "To form a dense neural network, we can simply feed the output of one dense layer into another dense layer as follows:\n",
    "\n",
    "$$ l_1 = \\sigma(x*W_1 + b_1)$$\n",
    "$$ l_2 = \\sigma(l_1*W_2 + b_2)$$\n",
    "$$ l_2 = \\sigma( \\sigma(x*W_1 + b_1) * W_2 + b_2) $$\n",
    "\n",
    "$\\sigma$ is an arbitrary non-linear function which has a first derivative. Common choices include:\n",
    "\n",
    "Sigmoid:\n",
    "\n",
    "$ \\begin{align} sigmoid(x) = \\frac{1}{1-e^{-x}} \\end{align}$\n",
    "\n",
    "ReLu (Rectified Linear Unit): \n",
    "\n",
    "$ \\begin{align} ReLu(x) = max(0,x) \\end{align}$\n",
    "\n",
    "and hyperbolic tangent function: \n",
    "\n",
    "$ \\begin{align} tanh(x) \\end{align}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 [10 points]\n",
    "\n",
    "Suppose that you have a dataset that contains 10 dimensions per sample. You want to use a single-layer neural network to classify this data into one of 3 different classes. To perform this classification, your neural network layer needs to produce an output vector $\\hat{y}$ with 3 dimensions, one for each class. \n",
    "\n",
    "Specify the shapes of your weight matrix $W$ and bias vector $b$ for this dataset. \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TODO: Answer here.\n",
    "W = (?,?)\n",
    "b = (1,?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Neural Network\n",
    "Let's start by building a two-layer DNN to classify our MNIST images. We would like our DNN to accept a 784-dimensional vector (28x28 image) and produce a 10-dimensional output vector $\\hat{y}$, where the $\\hat{y}[i]$ represents the probability that the given image is of digit $i$. \n",
    "\n",
    "To do this, we will use the `keras` package from `tensorflow`. Keras provides a high-level interface for quickly building neural networks. \n",
    "\n",
    "First, we need to create the layers for our DNN. We specified a two-layer neural network, with a final unit size of 10. \n",
    "\n",
    "We first need to create an `Input` layer, to define the dimensionality of our input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dims = 784\n",
    "input_layer = keras.Input(input_dims,name=\"input_layer\")\n",
    "print(input_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We have successfully built the input layer.\n",
    "\n",
    "Now, let's build the two neural network layers we need for our DNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4 [10 points]\n",
    "\n",
    "Fill in the output sizes for the two layers of our neural network. \n",
    "\n",
    "Layer 1 should have an output dimensionality of 64\n",
    "\n",
    "Layer 2 should have an output dimensionality of ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1_units = 64\n",
    "#layer_2_units = <your code here>\n",
    "\n",
    "dense_layer_1 = keras.layers.Dense(layer_1_units,activation=\"sigmoid\",name=\"dense_layer_1\")\n",
    "dense_layer_2 = keras.layers.Dense(layer_2_units,activation=\"softmax\",name=\"dense_layer_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5 [10 points]\n",
    "\n",
    "Create a list called `layers` which contains all of the layers we have created in order, starting with the input layer and ending with our final dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [input_layer,dense_layer_1,dense_layer_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can finally build our model!\n",
    "\n",
    "Let's create a Keras `Sequential` model object, so that we can link all of our created layers together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(layers=layers)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By calling `model.summary()` we can see a quick overview of our model's architecture. \n",
    "\n",
    "This model contains two layers: `dense_layer_1` and `dense_layer_2`, which are both dense layers.\n",
    "\n",
    "The `Output Shape` column contains tuples showing the output shape at each layer as a tuple of (N *(batch size)*, m *(output units)*). As mentioned previously, the batch size $N$ is an arbirtrary parameter, which we may choose during training. To represent this, keras places a `None` value in the batch dimension. The output units value $m$ for `dense_layer_1` is 64, since we determined this. The output units value $m$ for `dense_layer_2` should be the correct size for a classification with 10 classes.\n",
    "\n",
    "In the next step, we will fit the model using our training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_data_norm,train_labels,epochs=25,validation_data=(test_data_norm,test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `history` object is the return value for our call to `model.fit`. This object records the training and testing accuracy for our model.\n",
    "\n",
    "The `history.history` element is a dictionary containing lists of:\n",
    "- Loss - The model's average training loss at each epoch.\n",
    "- Accuracy - The model's training accuracy evaluated at each epoch.\n",
    "- Val Loss - The model's average validation (testing) loss at each epoch.\n",
    "- Val Accuracy - The model's validation accuracy at each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_dict = history.history\n",
    "print(hist_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6 [10 points]\n",
    "Now that we have the history for our model training saved in `hist_dict`, create two plots to visualize our model's performance.\n",
    "\n",
    "Plot 1 should compare the *training loss* and *testing loss* for during training. X-axis should be the epoch number, and Y-axis should be the values for training and testing loss. \n",
    "\n",
    "Plot 2 should compare *training accuracy* and *testing accuracy* during training. As above, X-axis should be epoch number, and Y-axis should be training/testing accuracy.\n",
    "\n",
    "Be sure to label your charts.\n",
    "\n",
    "What do you observe about the values for training and testing loss?\n",
    "Is training loss higher/lower than testing loss? Do you expect this result?\n",
    "Is training accuracy higher/lower than testing accuracy? Do you expect this result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Training/Testing Loss Chart Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Training/Testing Accuracy Chart Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Convolutional Neural Networks (CNNs)\n",
    "\n",
    "Convolutional neural networks (CNNs) are a specialized version of neural networks which may be used when there are spatial or temporal relationships between points in the input data.\n",
    "\n",
    "For example, in our digit images, pixels that are spatially close to each other often have related values (i.e., if one pixel has a high value, it is likely that others around it may also have high values).\n",
    "\n",
    "### Convolutional Layers\n",
    "Convolutional networks work by sliding small windows, called *filters*, containing trainable weights over the input data. These weights apply at multiple positions on the input image, wheras each weight from the DNN applies at only one position in the input data. This means that CNNs are capable of learning patterns that are invariant to position in the input. This is, for example, why an image classification network is capable of recognizing objects within images, even if the objects do not always appear in the same place in each image. \n",
    "\n",
    "![Convolutional Layer Animation](imgs/conv_layers.gif)\n",
    "*Image Credit: [Stanford CS231n](https://cs231n.github.io/convolutional-networks/)*\n",
    "\n",
    "In the above image, the *blue squares* represent a 5x5 image (7x7 with the zero padding) with three channels. The image is being convolved with 2 3x3 filters (the *red squares*), which each operate over all three channels. The convolution operation takes performs a weighted sum of the input image (*blue square*) values, using the filter values (*red squares*) as the weights. \n",
    "\n",
    "For a 3x3 input image window $I$:\n",
    "\n",
    "$$ \n",
    "I =  \\begin{bmatrix}\n",
    "            i_0 & i_1 & i_2\\\\\n",
    "            i_3 & i_4 & i_5\\\\\n",
    "            i_6 & i_7 & i_8\\\\\n",
    "       \\end{bmatrix} \n",
    "      $$\n",
    "\n",
    "and 3x3 filter $F$:\n",
    "\n",
    "$$ \n",
    "F =  \\begin{bmatrix}\n",
    "            f_0 & f_1 & f_2\\\\\n",
    "            f_3 & f_4 & f_5\\\\\n",
    "            f_6 & f_7 & f_8\\\\\n",
    "       \\end{bmatrix} \n",
    "      $$\n",
    "\n",
    "The resulting dot product can be written as: $$ dot =  i_0 \\cdot f_0 + i_1 \\cdot f_1 + \\ldots + i_8 \\cdot f_8 $$\n",
    "\n",
    "Note that this is *not* a matrix multiplication between $I$ and $F$, it is simply a dot product between the corresponding elements of $I$ and $F$, resulting in a single **scalar** output value. The dot products are applied over each channel, then summed together along with the scalar bias $b$ to return a single scalar value representing the activation for this location in the image. After this step, we would typically apply a non-linear activation $\\sigma$ as with the DNN example. The ReLu activation is the most common choice for activation function in CNNs.\n",
    "\n",
    "### Max Pooling Layer\n",
    "Another common feature of the Convolutional Neural Network is the Max Pooling layer. This layer works similarly to a convolutional layer, in that it slides a window across the data. However, the max pooling layer will select the largest (max) input from each window position, and discard the rest of the inputs. This means that only the highest activation value for each window position is kept. Max-pooling layers help to reduce the dimensionality of the data.\n",
    "\n",
    "![Max Pooling Example](imgs/maxpool.png)\n",
    "*Image Credit: [Computer Science Wiki](https://computersciencewiki.org/index.php/Max-pooling_/_Pooling)*\n",
    "\n",
    "Large state-of-the-art models contains large numbers of convolutional, max-pooling, and other types of layers (which we do not discuss here for sake of time).\n",
    "\n",
    "The image below is of the InceptionV3 architecture, which at one point was considered the state-of-the-art classifcation network for the ImageNet image dataset.\n",
    "\n",
    "![InceptionV3](imgs/Inception_V3.png)\n",
    "*Image Credit: [cloud.google.com](https://cloud.google.com/tpu/docs/inception-v3-advanced)*\n",
    "\n",
    "As you can see, this model architecture is complex, and contains millions of trainable parameters. Although we will not use it in this lab, the InceptionV3 architecture is also implemented as a pre-built architecture in Keras! Take a look at the [Keras documentation](https://keras.io/api/applications/inceptionv3/) for more information. \n",
    "\n",
    "If you are interested, also check out the [ImageNet Classification Ranking](https://paperswithcode.com/sota/image-classification-on-imagenet) for an up-to-date ranking of networks on the ImageNet dataset. Even though InceptionV3 was state-of-the-art when it was released in 2015, currently it only ranks 121st! This just goes to show the extremely rapid pace of research, iteration, and development in the Deep Learning field.\n",
    "\n",
    "In order to keep training time manageable for this lab, we will be implementing a (much) smaller architecture with two convolutional layers, two max-pooling layers, and a final classifcation dense layer.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7 [10 points]\n",
    "Right now our input data is in \"flattened\" form to be processed by our DNN. Since the CNN architecture can make use of the spatial relationships between pixels in our image, we need to reshape our data back to image format.\n",
    "\n",
    "For both `train_data_norm` and `test_data_norm`, create new variables `train_data_rsp` and `test_data_rsp` which reshape the data to be (num_samples, 28, 28, 1). This format stores each image in a 28x28x1 tensor (the final 1 represents the number of channels in the image. Our images are grayscale, so there is only 1 channel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Answer this question\n",
    "#train_data_rsp = <your code here>\n",
    "#test_data_rsp = <your code here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"conv_input_1:0\", shape=(None, 28, 28, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "conv_input_size = (28,28,1)\n",
    "conv_input_layer = keras.Input(conv_input_size,name=\"conv_input\")\n",
    "print(conv_input_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_1 = keras.layers.Conv2D(32, kernel_size=(3,3), activation=\"relu\",name=\"conv_layer_1\")\n",
    "maxpool_1 = keras.layers.MaxPooling2D(pool_size=(2,2),name=\"maxpool_1\")\n",
    "conv_layer_2 = keras.layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\",name=\"conv_layer_2\")\n",
    "maxpool_2 = keras.layers.MaxPooling2D(pool_size=(2,2),name=\"maxpool_2\")\n",
    "flatten = keras.layers.Flatten()\n",
    "conv_class_layer = keras.layers.Dense(10,activation=\"softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layers = [conv_input_layer,\n",
    "               conv_layer_1,\n",
    "               maxpool_1,\n",
    "               conv_layer_2,\n",
    "               maxpool_2,\n",
    "               flatten,\n",
    "               conv_class_layer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_layer_1 (Conv2D)        (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "maxpool_1 (MaxPooling2D)     (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_layer_2 (Conv2D)        (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "maxpool_2 (MaxPooling2D)     (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_model = keras.Sequential(layers=conv_layers)\n",
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data_rsp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-2cc5473d1a85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconv_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_rsp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_rsp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mconv_hist_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_hist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data_rsp' is not defined"
     ]
    }
   ],
   "source": [
    "conv_hist = conv_model.fit(train_data_rsp,train_labels,epochs=25,validation_data=(test_data_rsp,test_labels))\n",
    "conv_hist_dict = conv_hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conv_hist_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-1df3fb03a822>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_hist_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'conv_hist_dict' is not defined"
     ]
    }
   ],
   "source": [
    "print(conv_hist_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8 [10 points]\n",
    "\n",
    "Just as above, provide 2 plots visualizing the performance of the CNN on this dataset.\n",
    "\n",
    "Plot 1 should compare the *training loss* and *testing loss* for during training. X-axis should be the epoch number, and Y-axis should be the values for training and testing loss. \n",
    "\n",
    "Plot 2 should compare *training accuracy* and *testing accuracy* during training. As above, X-axis should be epoch number, and Y-axis should be training/testing accuracy.\n",
    "\n",
    "Be sure to label your charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Training/Testing Loss Chart Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Training/Testing Accuracy Chart Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9 [10 points]\n",
    "\n",
    "Answer the following questions with a few sentences each to discuss the performance of these two models.\n",
    "\n",
    "1. Which of the two models performed better on the testing data?\n",
    "    - Why do you think this is?\n",
    "\n",
    "2. Which model had fewer trainable parameters? \n",
    "\n",
    "3. What do trainable parameters values mean and how are they derived? (Trainable parameter values for each layer are found in the calls to `model.summary()` for the DNN model and `conv_model.summary()` for the CNN model.\n",
    "    - **HINT:** Add up the number of elements in both the weight and bias matrices, and compare to the trainable parameter size for each layer.\n",
    "4. Do you expect that the model with the largest number of parameters will always perform best?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TODO: Answer questions here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done! Save and submit your notebook on Canvas!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
